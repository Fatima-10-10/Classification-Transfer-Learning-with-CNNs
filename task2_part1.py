# -*- coding: utf-8 -*-
"""dl a3 t2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mMyGesLjyLqYPkZ7qD9lF9iiJwbWBGP6
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image


class Dataloader(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = sorted(os.listdir(root_dir))  # Get class labels from directory names
        self.class_to_label = {cls: i for i, cls in enumerate(self.classes)}  # Assign label to each class
        self.file_paths = self.get_file_paths()

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        image_path = self.file_paths[idx]
        image = Image.open(image_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        # Extract class label from the parent directory name
        label = self.class_to_label[os.path.basename(os.path.dirname(image_path))]

        return image, label

    def get_file_paths(self):
        file_paths = []
        for cls in self.classes:
            class_dir = os.path.join(self.root_dir, cls)
            files = os.listdir(class_dir)
            file_paths.extend([os.path.join(class_dir, file) for file in files])
        return file_paths


def split(root_dir, train_split=0.7, test_split=0.15, val_split=0.15):
    # Get list of all image file paths
    all_files = []
    for root, dirs, files in os.walk(root_dir):
        for file in files:
            if file.endswith(".bmp") or file.endswith(".jpg") or file.endswith(".png"):  # Adjust file extensions as needed
                all_files.append(os.path.join(root, file))

    # Shuffle the file paths
    np.random.shuffle(all_files)

    # Calculate split sizes
    num_files = len(all_files)
    train_size = int(train_split * num_files)
    test_size = int(test_split * num_files)
    val_size = num_files - train_size - test_size

    # Split the file paths
    train_files = all_files[:train_size]
    test_files = all_files[train_size:train_size + test_size]
    val_files = all_files[train_size + test_size:]

    return train_files, test_files, val_files



root_dir = '/content/drive/MyDrive/deep learning a3 data/image_classification'
train_files, test_files, val_files = split(root_dir)

print("Number of training images:", len(train_files))
print("Number of test images:", len(test_files))
print("Number of validation images:", len(val_files))

# Define transforms for data augmentation and normalization
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Create custom datasets
train_dataset = Dataloader(root_dir, transform=data_transform)
test_dataset = Dataloader(root_dir, transform=data_transform)
val_dataset = Dataloader(root_dir, transform=data_transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Example usage
for images, labels in train_loader:
    print(f'Images shape: {images.shape}')
    print(f'Labels shape: {labels.shape}')
    break

import torch
import torch.nn as nn

class VGG16(nn.Module):
    def __init__(self):
        super(VGG16, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))

        # Fully connected layers added below
        self.classifier = nn.Sequential(
            nn.Linear(7 * 7 * 512, 4096),  # First fully connected layer
            nn.ReLU(inplace=True),
            nn.Dropout(),  # Dropout layer
            nn.Linear(4096, 4096),  # Second fully connected layer
            nn.ReLU(inplace=True),
            nn.Dropout(),  # Dropout layer
            nn.Linear(4096, 1000),  # Third fully connected layer
            nn.Softmax(dim=1)  # Softmax activation
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Create an instance of the VGG16 model
model = VGG16()

# Freeze all convolutional blocks except the last one
def freeze_layers(model):
    for name, param in model.named_parameters():
        if 'features' in name:
            param.requires_grad = False
        elif 'classifier' in name:
            param.requires_grad = True
# Freeze layers
freeze_layers(model)

import torch

def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):
    train_loss_array = []
    train_accuracy_array = []
    val_loss_array = []
    val_accuracy_array = []

    # Device configuration
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        correct_train = 0
        total_train = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Compute training accuracy
            _, predicted = torch.max(outputs, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()

            train_loss += loss.item()

        train_accuracy = 100 * correct_train / total_train
        train_loss_array.append(train_loss / len(train_loader))
        train_accuracy_array.append(train_accuracy)

        # Evaluation on validation data
        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)

                outputs = model(images)
                loss = criterion(outputs, labels)

                # Compute validation accuracy
                _, predicted = torch.max(outputs, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()

                val_loss += loss.item()

        val_accuracy = 100 * correct_val / total_val
        val_loss_array.append(val_loss / len(val_loader))
        val_accuracy_array.append(val_accuracy)

        print(f'Epoch [{epoch + 1}/{num_epochs}], '
              f'Train Loss: {train_loss_array[-1]:.4f}, Train Accuracy: {train_accuracy:.2f}%, '
              f'Val Loss: {val_loss_array[-1]:.4f}, Val Accuracy: {val_accuracy:.2f}%')

    return model, train_loss_array, train_accuracy_array, val_loss_array, val_accuracy_array

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # You can adjust the learning rate

# Training the model
num_epochs = 5  # Adjust the number of epochs as needed
trained_model, train_loss, train_accuracy, val_loss, val_accuracy = train(model, train_loader, val_loader, criterion, optimizer, num_epochs)

def test(model, test_loader):
    model.eval()
    predictions = []
    true_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.tolist())
            true_labels.extend(torch.argmax(labels, 1).tolist())

    return predictions, true_labels

def plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies):
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss Curves')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label='Train Accuracy')
    plt.plot(val_accuracies, label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Accuracy Curves')
    plt.legend()

    plt.show()

def plot_confusion_matrix(y_true, y_pred, classes):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)

    fmt = 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()

def visualize_predictions(images, true_labels, predicted_labels, class_names):
    num_images = len(images)
    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))
    fig.subplots_adjust(hspace=0.6, wspace=0.3)
    for i, ax in enumerate(axes.flat):
        if i < num_images:
            ax.imshow(images[i], cmap='binary')
            if true_labels[i] == predicted_labels[i]:
                ax.set_title(f'True: {class_names[true_labels[i]]}\nPred: {class_names[predicted_labels[i]]}', color='green')
            else:
                ax.set_title(f'True: {class_names[true_labels[i]]}\nPred: {class_names[predicted_labels[i]]}', color='red')
        ax.axis('off')
    plt.show()

import torch.optim as optim
# Training the model
model.train()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.1)
epochs=10
trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, val_loader, criterion, optimizer, num_epochs=epochs)

# Plotting loss and accuracy curves
plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies)

# Testing the model
predictions, true_labels = test(trained_model, test_loader)



import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image

def save_model(model, filepath):
    torch.save(model.state_dict(), filepath)
    print("Model saved successfully.")

def load_model(model_class, filepath):
    model = model_class()
    model.load_state_dict(torch.load(filepath))
    print("Model loaded successfully.")
    return model

def test(model, test_loader):
    model.eval()
    predictions = []
    true_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.tolist())
            true_labels.extend(labels.tolist())

    return predictions, true_labels

def runtime_testing(model, image_path, transform):
    model.eval()
    image = Image.open(image_path).convert('L')  # Convert to grayscale
    image = transform(image).unsqueeze(0)  # Add batch dimension
    output = model(image)
    prediction = torch.argmax(F.softmax(output, dim=1), dim=1).item()
    return prediction

# Save the model
save_model(model, '/content/drive/MyDrive/deep learning a3 data/task2')

# Load the model
loaded_model = load_model(CNNModel, '/content/drive/MyDrive/deep learning a3 data/task2')

# Test the model
predictions, true_labels = test(loaded_model, test_loader)

# Runtime testing
image_path = '/content/drive/MyDrive/deep learning a3 data/mnist/dla3_test/test/1.png'  # Replace with the path to your input image
predicted_label = runtime_testing(loaded_model, image_path, transform)
print("Predicted label:", predicted_label)

# Assuming `test_model` function returns predictions and true labels
predictions, true_labels = test(loaded_model, test_loader)

# Calculating metrics
accuracy = accuracy_score(true_labels, predictions)
f1 = f1_score(true_labels, predictions, average='macro')

print(f'Test Accuracy: {accuracy:.2f}')
print(f'F1 Score: {f1:.2f}')

def visualize_metrics(accuracy, f1):
    # Plotting accuracy and F1 score
    plt.figure(figsize=(8, 5))
    plt.bar(['Accuracy', 'F1 Score'], [accuracy, f1], color=['blue', 'green'])
    plt.xlabel('Metrics')
    plt.ylabel('Score')
    plt.title('Accuracy and F1 Score')
    plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
    plt.show()

# Plot accuracy and F1 score
visualize_metrics(accuracy, f1)

# Plotting confusion matrix
class_names = [str(i) for i in range(10)]
plot_confusion_matrix(true_labels, predictions, class_names)

def visualize_predictions(images, true_labels, predicted_labels, class_names):
    # Display 5 accurate predictions
    accurate_indices = [i for i in range(len(true_labels)) if true_labels[i] == predicted_labels[i]]

    fig, axes = plt.subplots(2, 5, figsize=(12, 6))
    fig.subplots_adjust(hspace=0.6, wspace=0.3)

    for i in range(5):
        ax = axes[0, i]
        ax.imshow(images[accurate_indices[i]], cmap='binary')
        ax.set_title(f'True: {class_names[true_labels[accurate_indices[i]]]}\nPred: {class_names[predicted_labels[accurate_indices[i]]]}')
        ax.axis('off')

    # Display 5 wrong predictions
    wrong_indices = [i for i in range(len(true_labels)) if true_labels[i] != predicted_labels[i]]

    for i in range(5):
        ax = axes[1, i]
        ax.imshow(images[wrong_indices[i]], cmap='binary')
        ax.set_title(f'True: {class_names[true_labels[wrong_indices[i]]]}\nPred: {class_names[predicted_labels[wrong_indices[i]]]}')
        ax.axis('off')

    plt.show()

# Extract a subset of data from the test dataset
num_images_to_visualize = 10  # Number of images to visualize
images_to_visualize = []
true_labels_to_visualize = []
predicted_labels_to_visualize = []

# Get a subset of data from the test loader
for i, (images, labels) in enumerate(test_loader):
    images_to_visualize.extend(images.numpy())
    true_labels_to_visualize.extend(labels.numpy())
    predicted_labels_to_visualize.extend(predictions[i * len(images):(i + 1) * len(images)])

    if len(images_to_visualize) >= num_images_to_visualize:
        break

# Reshape images to (28, 28)
images_to_visualize = [image.reshape(28, 28) for image in images_to_visualize]

# Call visualize_predictions function
class_names = [str(i) for i in range(10)]
visualize_predictions(images_to_visualize, true_labels_to_visualize, predicted_labels_to_visualize, class_names)

